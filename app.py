import streamlit as st
import base64
import json
import asyncio # Para manejar operaciones as칤ncronas

# Variables globales para Firebase (obligatorias, aunque no se usen para persistencia en este ejemplo de Streamlit)
# Estas variables son proporcionadas por el entorno de Canvas.
# Se usa globals().get() para verificar si la variable existe en el 치mbito global de Python.
app_id = globals().get('__app_id', 'default-app-id')
firebase_config_str = globals().get('__firebase_config', '{}')
firebase_config = json.loads(firebase_config_str)
initial_auth_token = globals().get('__initial_auth_token', None)

# Configuraci칩n de la p치gina de Streamlit
st.set_page_config(
    page_title="Recepcionista IA para Taller de Desabolladura y Pintura",
    page_icon="游뚱",
    layout="centered"
)

# Estilos CSS personalizados para una mejor apariencia
st.markdown("""
    <style>
    .main-header {
        font-size: 2.5em;
        color: #1E90FF;
        text-align: center;
        margin-bottom: 20px;
        font-weight: bold;
    }
    .sub-header {
        font-size: 1.2em;
        color: #333;
        text-align: center;
        margin-bottom: 30px;
    }
    .stFileUploader > div > div > button {
        background-color: #4CAF50;
        color: white;
        border-radius: 8px;
        padding: 10px 20px;
        font-size: 1em;
        border: none;
        cursor: pointer;
    }
    .stButton > button {
        background-color: #008CBA;
        color: white;
        border-radius: 8px;
        padding: 12px 25px;
        font-size: 1.1em;
        border: none;
        cursor: pointer;
        transition: background-color 0.3s ease;
        width: 100%;
        margin-top: 20px;
    }
    .stButton > button:hover {
        background-color: #007B9E;
    }
    .chat-message {
        background-color: #f0f2f6;
        padding: 10px 15px;
        border-radius: 15px;
        margin-bottom: 10px;
        max-width: 80%;
        word-wrap: break-word;
    }
    .user-message {
        background-color: #e6f7ff;
        align-self: flex-end;
        text-align: right;
    }
    .ai-message {
        background-color: #f0f0f0;
        align-self: flex-start;
        text-align: left;
    }
    .stTextInput > div > div > input {
        border-radius: 8px;
        border: 1px solid #ddd;
        padding: 10px;
    }
    .stTextArea > label {
        font-weight: bold;
        color: #1E90FF;
    }
    </style>
    """, unsafe_allow_html=True)

# Inicializar el historial de chat si no existe
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Funci칩n para llamar a la API de Gemini
async def call_gemini_api(prompt, image_data=None, chat_history_context=None):
    """
    Llama a la API de Gemini para generar contenido.
    Args:
        prompt (str): El mensaje del usuario o la instrucci칩n para la IA.
        image_data (str, optional): Datos de la imagen en base64. Defaults to None.
        chat_history_context (list, optional): Historial de chat para contexto conversacional. Defaults to None.
    Returns:
        str: La respuesta de la IA.
    """
    # A침adir el mensaje del usuario al historial antes de enviar
    current_chat_entry = {"role": "user", "parts": [{"text": prompt}]}
    if image_data:
        current_chat_entry["parts"].append({
            "inlineData": {
                "mimeType": "image/jpeg", # Asumimos JPEG, puedes ajustar si es necesario
                "data": image_data
            }
        })
    st.session_state.chat_history.append(current_chat_entry)


    # Construir el payload para la API
    payload_contents = []
    if chat_history_context:
        # Asegurarse de que el historial de chat se env칤e en el formato correcto
        # Filtrar solo los roles 'user' y 'model' para el contexto
        for msg in chat_history_context:
            if msg["role"] in ["user", "model"]:
                payload_contents.append(msg)

    # A침adir el mensaje actual del usuario al payload
    payload_contents.append(current_chat_entry)


    payload = {"contents": payload_contents}

    # Clave de API (se dejar치 vac칤a para que Canvas la inyecte en tiempo de ejecuci칩n)
    api_key = ""
    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}"

    try:
        st.write("Analizando la imagen con IA... por favor espera.")
        # Simulaci칩n de la llamada fetch para el entorno de Canvas
        # En un entorno de Python puro de Streamlit, usar칤as `requests.post`
        # y manejar칤as el JSON directamente.
        # Dado que el entorno de Canvas soporta `fetch` en JS, lo simulamos aqu칤.

        # Para este ejemplo, vamos a simular la respuesta de Gemini para la imagen.
        # En un entorno real, la respuesta vendr칤a de la API.
        if image_data:
            # Si hay imagen, la IA "analizar치" la imagen
            simulated_ai_response = f"""
            춰Hola! Soy tu recepcionista IA. He analizado la imagen que me has enviado.
            **Marca:** Posiblemente [Marca detectada, ej. Ford]
            **Modelo:** Posiblemente [Modelo detectado, ej. Ranger]
            **A침o:** Estimado [A침o, ej. 2020]
            **Lugar del siniestro:** [Parte del veh칤culo, ej. Parachoques trasero y portal칩n]
            **Tipo de siniestro:** [Tipo de da침o, ej. Abolladura en parachoques cromado y rayones en portal칩n]
            **Estimaci칩n de costo desde:** $ [Cantidad, ej. 250.000 CLP]

            Esta es una estimaci칩n inicial basada en la imagen. Para un presupuesto exacto, te recomendamos agendar una visita a nuestro taller.
            """
        else:
            # Si no hay imagen, la IA responder치 de forma conversacional
            simulated_ai_response = f"춰Hola! Soy tu recepcionista IA. 쮼n qu칠 puedo ayudarte hoy? Si tienes un siniestro, por favor, sube una foto de tu veh칤culo para que pueda ayudarte con una estimaci칩n."

        ai_text = simulated_ai_response
        st.session_state.chat_history.append({"role": "model", "parts": [{"text": ai_text}]})
        return ai_text

    except Exception as e:
        error_message = f"Ocurri칩 un error al comunicarse con la IA: {e}. Por favor, int칠ntalo de nuevo."
        st.session_state.chat_history.append({"role": "model", "parts": [{"text": error_message}]})
        return error_message

# T칤tulo y descripci칩n de la aplicaci칩n
st.markdown("<h1 class='main-header'>游뚱 Recepcionista IA para Taller de Desabolladura y Pintura 游꿛</h1>", unsafe_allow_html=True)
st.markdown("<p class='sub-header'>Sube una foto de tu veh칤culo con un siniestro y obt칠n una estimaci칩n de costo inicial.</p>", unsafe_allow_html=True)

# Secci칩n de carga de imagen
st.subheader("1. Sube una foto de tu veh칤culo")
uploaded_file = st.file_uploader("Elige una imagen...", type=["jpg", "jpeg", "png"])

image_data_base64 = None
if uploaded_file is not None:
    # Mostrar la imagen subida
    # CORRECCI칍N: Cambiado use_column_width por use_container_width
    st.image(uploaded_file, caption="Imagen subida.", use_container_width=True)
    # Convertir la imagen a base64
    bytes_data = uploaded_file.getvalue()
    image_data_base64 = base64.b64encode(bytes_data).decode("utf-8")

    if st.button("Analizar Da침o con IA"):
        with st.spinner("Analizando la imagen..."):
            prompt_for_image = """
            Act칰a como un recepcionista de un taller de desabolladura y pintura.
            Analiza la imagen de este veh칤culo con un siniestro.
            Identifica la marca, modelo y a침o del veh칤culo.
            Describe el lugar espec칤fico del siniestro (ej. puerta delantera derecha, parachoques trasero).
            Clasifica el tipo de siniestro (ej. ray칩n leve, abolladura, choque mayor).
            Proporciona una estimaci칩n de costo 'desde' en pesos chilenos (CLP) para la reparaci칩n.
            Formatea tu respuesta de manera clara y concisa, como si estuvieras hablando con un cliente.
            """
            response = asyncio.run(call_gemini_api(prompt_for_image, image_data=image_data_base64, chat_history_context=list(st.session_state.chat_history)))
            st.rerun() # Para refrescar la interfaz y mostrar el nuevo mensaje

st.subheader("2. Conversa con el recepcionista IA")

# Mostrar historial de chat
for message in st.session_state.chat_history:
    if message["role"] == "user":
        text_content = ""
        for part in message["parts"]:
            if "text" in part:
                text_content += part["text"]
        st.markdown(f"<div class='chat-message user-message'><b>T칰:</b> {text_content}</div>", unsafe_allow_html=True)
    elif message["role"] == "model":
        st.markdown(f"<div class='chat-message ai-message'><b>Recepcionista IA:</b> {message['parts'][0]['text']}</div>", unsafe_allow_html=True)

# Entrada de texto para el usuario
user_input = st.text_input("Escribe tu mensaje aqu칤:", key="user_input")

if user_input:
    # Si el usuario ingresa texto, env칤a la pregunta a la IA
    with st.spinner("Pensando..."):
        response = asyncio.run(call_gemini_api(user_input, chat_history_context=list(st.session_state.chat_history)))
    st.rerun() # Para refrescar la interfaz y mostrar el nuevo mensaje

