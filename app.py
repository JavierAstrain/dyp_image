import streamlit as st
import base64
import json
import asyncio # Para manejar operaciones as칤ncronas
import requests # Necesario para hacer llamadas HTTP a la API de Gemini

# Variables globales para Firebase (obligatorias, aunque no se usen para persistencia en este ejemplo de Streamlit)
# Estas variables son proporcionadas por el entorno de Canvas.
# Se usa globals().get() para verificar si la variable existe en el 치mbito global de Python.
app_id = globals().get('__app_id', 'default-app-id')
firebase_config_str = globals().get('__firebase_config', '{}')
firebase_config = json.loads(firebase_config_str)
initial_auth_token = globals().get('__initial_auth_token', None)

# Configuraci칩n de la p치gina de Streamlit
st.set_page_config(
    page_title="Recepcionista IA para Taller de Desabolladura y Pintura",
    page_icon="游뚱",
    layout="centered"
)

# Estilos CSS personalizados para una mejor apariencia
st.markdown("""
    <style>
    .main-header {
        font-size: 2.5em;
        color: #1E90FF;
        text-align: center;
        margin-bottom: 20px;
        font-weight: bold;
    }
    .sub-header {
        font-size: 1.2em;
        color: #333;
        text-align: center;
        margin-bottom: 30px;
    }
    .stFileUploader > div > div > button {
        background-color: #4CAF50;
        color: white;
        border-radius: 8px;
        padding: 10px 20px;
        font-size: 1em;
        border: none;
        cursor: pointer;
    }
    .stButton > button {
        background-color: #008CBA;
        color: white;
        border-radius: 8px;
        padding: 12px 25px;
        font-size: 1.1em;
        border: none;
        cursor: pointer;
        transition: background-color 0.3s ease;
        width: 100%;
        margin-top: 20px;
    }
    .stButton > button:hover {
        background-color: #007B9E;
    }
    .chat-message {
        background-color: #f0f2f6;
        padding: 10px 15px;
        border-radius: 15px;
        margin-bottom: 10px;
        max-width: 80%;
        word-wrap: break-word;
    }
    .user-message {
        background-color: #e6f7ff;
        align-self: flex-end;
        text-align: right;
    }
    .ai-message {
        background-color: #f0f0f0;
        align-self: flex-start;
        text-align: left;
    }
    .stTextInput > div > div > input {
        border-radius: 8px;
        border: 1px solid #ddd;
        padding: 10px;
    }
    .stTextArea > label {
        font-weight: bold;
        color: #1E90FF;
    }
    </style>
    """, unsafe_allow_html=True)

# Inicializar el historial de chat si no existe
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Funci칩n para llamar a la API de Gemini
async def call_gemini_api(prompt_text, image_data=None, chat_history_context=None):
    """
    Llama a la API de Gemini para generar contenido.
    Args:
        prompt_text (str): El mensaje del usuario o la instrucci칩n para la IA.
        image_data (str, optional): Datos de la imagen en base64. Defaults to None.
        chat_history_context (list, optional): Historial de chat para contexto conversacional. Defaults to None.
    Returns:
        str: La respuesta de la IA.
    """
    # Construir el payload para la API
    payload_contents = []

    # A침adir el historial de chat para contexto conversacional
    if chat_history_context:
        for msg in chat_history_context:
            if msg["role"] in ["user", "model"]:
                payload_contents.append(msg)

    # A침adir el mensaje actual del usuario al payload
    user_parts = [{"text": prompt_text}]
    if image_data:
        user_parts.append({
            "inlineData": {
                "mimeType": "image/jpeg", # Asumimos JPEG, puedes ajustar si es necesario
                "data": image_data
            }
        })
    payload_contents.append({"role": "user", "parts": user_parts})

    payload = {"contents": payload_contents}

    # Leer la API Key de Streamlit Secrets o dejarla vac칤a para el entorno de Canvas
    try:
        api_key = st.secrets["GEMINI_API_KEY"]
    except KeyError:
        api_key = "" # Deja esto vac칤o si dependes de la inyecci칩n de Canvas o si no tienes una clave local.
        # st.warning("No se encontr칩 'GEMINI_API_KEY' en `secrets.toml`. La aplicaci칩n podr칤a no funcionar correctamente sin una clave de API.")


    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}"

    try:
        # st.write("Analizando con IA... por favor espera.") # Esto ya se maneja con st.spinner
        headers = {'Content-Type': 'application/json'}
        response = requests.post(api_url, headers=headers, json=payload)
        result = response.json()

        ai_text = "No pude obtener una respuesta de la IA. Int칠ntalo de nuevo."
        if result.get("candidates") and result["candidates"][0].get("content") and result["candidates"][0]["content"].get("parts"):
            ai_text = result["candidates"][0]["content"]["parts"][0]["text"]

        # Para el prop칩sito de este demo, a칰n mantendremos la simulaci칩n para la valoraci칩n detallada
        # ya que Gemini-2.0-flash no est치 entrenado espec칤ficamente para cuantificar da침os vehiculares.
        if image_data:
            simulated_ai_response = f"""
            춰Hola! Soy tu recepcionista IA. He analizado la imagen que me has enviado.
            **Marca:** Posiblemente [Marca detectada, ej. Ford]
            **Modelo:** Posiblemente [Modelo detectado, ej. Ranger]
            **A침o:** Estimado [A침o, ej. 2020]
            **Lugar del siniestro:** [Parte del veh칤culo, ej. Parachoques trasero y portal칩n]
            **Tipo de siniestro:** [Tipo de da침o, ej. Abolladura en parachoques cromado y rayones en portal칩n]
            **Estimaci칩n de costo desde:** $ [Cantidad, ej. 250.000 CLP]

            Esta es una **estimaci칩n inicial basada en la imagen simulada**. Para un presupuesto exacto y definitivo, te recomendamos encarecidamente agendar una visita a nuestro taller para una inspecci칩n f칤sica detallada.
            """
            # Combinamos la respuesta real de Gemini (si la hay) con la simulaci칩n
            # Solo si Gemini dio una respuesta diferente a la predeterminada, la agregamos.
            if ai_text != "No pude obtener una respuesta de la IA. Int칠ntalo de nuevo.":
                 ai_text = simulated_ai_response + "\n\n**An치lisis general de Gemini:** " + ai_text
            else:
                 ai_text = simulated_ai_response # Si Gemini no dio una respuesta 칰til, solo usamos la simulaci칩n
        else:
            # Si no hay imagen, la IA responder치 de forma conversacional usando la respuesta real de Gemini
            pass # ai_text ya contiene la respuesta de Gemini o el mensaje de error

        st.session_state.chat_history.append({"role": "model", "parts": [{"text": ai_text}]})
        return ai_text

    except Exception as e:
        error_message = f"Ocurri칩 un error al comunicarse con la IA: {e}. Por favor, int칠ntalo de nuevo."
        st.session_state.chat_history.append({"role": "model", "parts": [{"text": error_message}]})
        return error_message

# T칤tulo y descripci칩n de la aplicaci칩n
st.markdown("<h1 class='main-header'>游뚱 Recepcionista IA para Taller de Desabolladura y Pintura 游꿛</h1>", unsafe_allow_html=True)
st.markdown("<p class='sub-header'>Sube una foto de tu veh칤culo con un siniestro y obt칠n una estimaci칩n de costo inicial.</p>", unsafe_allow_html=True)

# Secci칩n de carga de imagen
st.subheader("1. Sube una foto de tu veh칤culo")
uploaded_file = st.file_uploader("Elige una imagen...", type=["jpg", "jpeg", "png"])

image_data_base64 = None
if uploaded_file is not None:
    # Mostrar la imagen subida
    st.image(uploaded_file, caption="Imagen subida.", use_container_width=True)
    # Convertir la imagen a base64
    bytes_data = uploaded_file.getvalue()
    image_data_base64 = base64.b64encode(bytes_data).decode("utf-8")

    if st.button("Analizar Da침o con IA"):
        # A침adir un mensaje de usuario al historial indicando que se subi칩 una imagen
        st.session_state.chat_history.append({"role": "user", "parts": [{"text": "He subido una imagen de mi veh칤culo para an치lisis."}]})

        with st.spinner("Analizando la imagen..."):
            # Este es el prompt interno para la IA, no se muestra al usuario directamente en el chat
            prompt_for_image_analysis = """
            Act칰a como un recepcionista de un taller de desabolladura y pintura.
            Analiza la imagen de este veh칤culo con un siniestro.
            Describe lo que ves en la imagen en t칠rminos de tipo de veh칤culo, color, y la naturaleza general del da침o.
            No intentes identificar marca, modelo, a침o o dar una estimaci칩n de costo aqu칤, solo una descripci칩n general.
            """
            response = asyncio.run(call_gemini_api(prompt_for_image_analysis, image_data=image_data_base64, chat_history_context=list(st.session_state.chat_history)))
            st.rerun() # Para refrescar la interfaz y mostrar el nuevo mensaje

st.subheader("2. Conversa con el recepcionista IA")

# Mostrar historial de chat
for message in st.session_state.chat_history:
    if message["role"] == "user":
        text_content = ""
        for part in message["parts"]:
            if "text" in part:
                text_content += part["text"]
        st.markdown(f"<div class='chat-message user-message'><b>T칰:</b> {text_content}</div>", unsafe_allow_html=True)
    elif message["role"] == "model":
        st.markdown(f"<div class='chat-message ai-message'><b>Recepcionista IA:</b> {message['parts'][0]['text']}</div>", unsafe_allow_html=True)

# Entrada de texto para el usuario
user_input = st.text_input("Escribe tu mensaje aqu칤:", key="user_input")

if user_input:
    # Si el usuario ingresa texto, a침ade el mensaje al historial de chat
    st.session_state.chat_history.append({"role": "user", "parts": [{"text": user_input}]})
    with st.spinner("Pensando..."):
        # Se env칤a el historial completo para que la IA tenga contexto
        response = asyncio.run(call_gemini_api(user_input, chat_history_context=list(st.session_state.chat_history)))
    st.rerun() # Para refrescar la interfaz y mostrar el nuevo mensaje
